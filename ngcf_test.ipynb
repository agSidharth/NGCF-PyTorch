{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "256cbd64-b105-4c17-878b-689c96053c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from numpy.linalg import norm\n",
    "print(torch.__version__)\n",
    "\n",
    "train_pth = \"./Data/gowalla/train.txt\"\n",
    "test_pth = \"./Data/gowalla/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2e6d837-4820-4607-b7c0-04498f7bd1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len_train_items = []\n",
    "\n",
    "with open(train_pth) as f:\n",
    "    for l in f.readlines():\n",
    "        if len(l) > 0:\n",
    "            l = l.strip('\\n').split(' ')\n",
    "            items = [int(i) for i in l[1:]]\n",
    "            uid = int(l[0])\n",
    "            len_train_items.append(len(items))\n",
    "            \n",
    "len_test_items = []\n",
    "\n",
    "with open(test_pth) as f:\n",
    "    for l in f.readlines():\n",
    "        if len(l) > 0:\n",
    "            l = l.strip('\\n').split(' ')\n",
    "            items = [int(i) for i in l[1:]]\n",
    "            uid = int(l[0])\n",
    "            len_test_items.append(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcc028f8-0800-4186-b743-f6c027a85f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len_train_items = np.array(len_train_items)\n",
    "len_test_items = np.array(len_test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fc2f718-251a-443c-9248-6d1ed3ecece4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2519685 , 0.26530612, 0.26190476, ..., 0.27272727, 0.28125   ,\n",
       "       0.25      ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test_items/len_train_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57d50200-b76c-4a2f-bd3a-f15c86f33063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_dataframe(city, verbose=False, source = False, useSaved = True):\n",
    "    \n",
    "    check_path = f\"/home/ttgn/tgn-master/data/TIST/df_\" + city + \".csv\"\n",
    "    \n",
    "    if os.path.isfile(check_path) and useSaved:\n",
    "        df_review = pd.read_csv(check_path)\n",
    "        return df_review\n",
    "    \n",
    "    # city_name must be in \"London\" format\n",
    "    df_review = df_merged[df_merged['city_name']==city]\n",
    "    \n",
    "    USER_MIN_CONNECTIONS = 2\n",
    "    BUSINESSES_MIN_CONNECTIONS = 20\n",
    "    \n",
    "#     if source:\n",
    "#         USER_MIN_CONNECTIONS = 20\n",
    "#         BUSINESSES_MIN_CONNECTIONS = 10\n",
    "    \n",
    "    print(USER_MIN_CONNECTIONS,BUSINESSES_MIN_CONNECTIONS)\n",
    "    \n",
    "    top_users = df_review['user_id'].value_counts()\n",
    "    #print(len(top_users))\n",
    "    top_users = set(list(top_users[top_users>=USER_MIN_CONNECTIONS].index))\n",
    "    #print(len(top_users))\n",
    "    df_review = df_review[(df_review['user_id'].isin(top_users))]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"After removing inactive users :\",df_review.shape)\n",
    "    \n",
    "    top_businesses = df_review['venue_id'].value_counts()\n",
    "    #print(len(top_businesses))\n",
    "    top_businesses = set(list(top_businesses[top_businesses>=BUSINESSES_MIN_CONNECTIONS].index))\n",
    "    #print(len(top_businesses))\n",
    "    df_review = df_review[(df_review['venue_id'].isin(top_businesses))]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"After removing inactive venues\",df_review.shape)\n",
    "    \n",
    "    df_review['utc'] = pd.to_datetime(df_review['utc'],errors = 'coerce')\n",
    "    df_review['time_zone'] = pd.to_timedelta(df_review['time_zone'],'m')\n",
    "    df_review['local_time'] = df_review['utc'] + df_review['time_zone']\n",
    "    df_review.dropna(subset = 'local_time',inplace = True)\n",
    "    \n",
    "    start_time = min(df_review.local_time)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"start time\", start_time)\n",
    "    df_review['ts'] = (df_review['local_time']-start_time).astype('timedelta64[h]')\n",
    "    df_review['ts'] = (df_review['ts']*1).astype(int)\n",
    "    df_review.sort_values('ts',inplace=True)\n",
    "    \n",
    "    df_review['u'] = pd.factorize(df_review['user_id'])[0] + 1\n",
    "    df_review['i'] = pd.factorize(df_review['venue_id'])[0]+ 1 + max(df_review['u'])\n",
    "    df_review['label'] = [1]*df_review.shape[0]\n",
    "    df_review['idx'] = np.arange(1,df_review.shape[0]+1)\n",
    "    \n",
    "    df_review[['u','i','ts','label','idx']].to_csv(\"/home/ttgn/data/ml_4square_{}.csv\".format(city),index=False)\n",
    "    \n",
    "    totalReviews = df_review.shape[0]\n",
    "    embeddings = np.zeros((totalReviews,9))\n",
    "    \n",
    "    if verbose:\n",
    "        print(embeddings.shape)\n",
    "    \n",
    "    empty = np.zeros(embeddings.shape[1])[np.newaxis,:]\n",
    "    feat = np.vstack([empty,embeddings])\n",
    "    \n",
    "    if verbose:\n",
    "        print(feat.shape)\n",
    "    \n",
    "    max_idx = max(df_review.u.max(), df_review.i.max())\n",
    "    \n",
    "    if verbose:\n",
    "        print(max_idx)\n",
    "    rand_feat = np.zeros((max_idx+1,embeddings.shape[1]))\n",
    "    \n",
    "    if verbose:\n",
    "        print(rand_feat.shape)\n",
    "\n",
    "    np.save(\"/home/ttgn/data/ml_4square_{}.npy\".format(city), feat)\n",
    "    np.save(\"/home/ttgn/data/ml_4square_{}_node.npy\".format(city), rand_feat)\n",
    "    \n",
    "    #df_tmp.to_csv(f\"/home/ttgn/data/TIST/df_\" + city_name + \".csv\")\n",
    "    df_review.to_csv(f\"/home/ttgn/tgn-master/data/TIST/df_\" + city + \".csv\")\n",
    "    return df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc0129ec-33e8-4691-a9f4-114762563076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data_ngcf(city_name):\n",
    "    \n",
    "    df_city = save_dataframe(city_name)\n",
    "    df_city['u'] -= 1\n",
    "    df_city['i'] -= min(df_city['i'])\n",
    "    \n",
    "    total_rows = len(df_city)\n",
    "    first_10_percent = int(0.10 * total_rows)\n",
    "    last_45_percent = int(0.45 * total_rows)\n",
    "    \n",
    "    df_train = df_city.head(first_10_percent)\n",
    "    df_test = df_city.tail(last_45_percent)\n",
    "    \n",
    "    result = df_city.groupby('u')['i'].unique().apply(list).to_dict()\n",
    "    \n",
    "    result_train = df_train.groupby('u')['i'].apply(list).to_dict()\n",
    "    result_test = df_test.groupby('u')['i'].apply(list).to_dict()\n",
    "    \n",
    "    train_data = result.copy()\n",
    "    test_data = result.copy()\n",
    "\n",
    "    for key, values in train_data.items():\n",
    "        if key not in result_train:\n",
    "            train_data[key] = []\n",
    "        else:\n",
    "            train_data[key] = result_train[key]\n",
    "        \n",
    "    for key, values in test_data.items():\n",
    "        if key not in result_test:\n",
    "            test_data[key] = []\n",
    "        else:\n",
    "            test_data[key] = result_test[key]\n",
    "\n",
    "\n",
    "    folder_path = f'./Data/four-square-{city_name}/'\n",
    "        \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "\n",
    "    # Writing to train.txt\n",
    "    with open(f'./Data/four-square-{city_name}/train.txt', 'w') as train_file:\n",
    "        for key in sorted(train_data.keys()):\n",
    "            train_file.write(f\"{key} {' '.join(map(str, train_data[key]))}\\n\")\n",
    "\n",
    "    # Writing to test.txt\n",
    "    with open(f'./Data/four-square-{city_name}/test.txt',  'w') as test_file:\n",
    "        for key in sorted(test_data.keys()):\n",
    "            test_file.write(f\"{key} {' '.join(map(str, test_data[key]))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cc0f703f-279b-4e5a-883c-91f39a1d7586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for city in [\"London\",\"Brooklyn\",\"Toronto\",\"New York\",\"Madrid\",\"Los Angeles\",\"Barcelona\",\"Tokyo\"]:\n",
    "    generate_data_ngcf(city)\n",
    "    \n",
    "# \"Brooklyn\",\"Toronto\",\"New York\",\"Madrid\",\"Los Angeles\",\"Barcelona\",\"Tokyo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea63207b-fb5c-4059-b054-6dea1c07e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_data_ngcf(city_name):\n",
    "    \n",
    "#     df_city = save_dataframe(city_name)\n",
    "#     df_city['u'] -= 1\n",
    "#     df_city['i'] -= min(df_city['i'])\n",
    "    \n",
    "#     total_rows = len(df_city)\n",
    "#     first_10_percent = int(0.10 * total_rows)\n",
    "#     last_45_percent = int(0.45 * total_rows)\n",
    "    \n",
    "#     df_train = df_city.head(first_10_percent)\n",
    "#     df_test = df_city.tail(last_45_percent)\n",
    "    \n",
    "#     result_train = df_train.groupby('u')['i'].unique().apply(list).to_dict()\n",
    "#     result_test = df_test.groupby('u')['i'].unique().apply(list).to_dict()\n",
    "    \n",
    "#     print(len(result_train, result_test))\n",
    "    \n",
    "#     train_data = {}\n",
    "#     test_data = {}\n",
    "\n",
    "#     for key, values in result_train.items():\n",
    "#         train_data[key] = values\n",
    "        \n",
    "#     for key, values in result_test.items():\n",
    "#         test_data[key] = values\n",
    "\n",
    "\n",
    "#     folder_path = f'./Data/four-square-{city_name}/'\n",
    "        \n",
    "#     if not os.path.exists(folder_path):\n",
    "#         os.mkdir(folder_path)\n",
    "\n",
    "#     # Writing to train.txt\n",
    "#     with open(f'./Data/four-square-{city_name}/train.txt', 'w') as train_file:\n",
    "#         for key in sorted(train_data.keys()):\n",
    "#             train_file.write(f\"{key} {' '.join(map(str, train_data[key]))}\\n\")\n",
    "\n",
    "#     # Writing to test.txt\n",
    "#     with open(f'./Data/four-square-{city_name}/test.txt',  'w') as test_file:\n",
    "#         for key in sorted(test_data.keys()):\n",
    "#             test_file.write(f\"{key} {' '.join(map(str, test_data[key]))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1babba-6071-4541-a756-c7c6be6db3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
